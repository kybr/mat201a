{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MAT 201A Spring 2017\n",
      "HW 2\n",
      "Appannacharya Kalyan Tej Javvadi\n",
      "ajavvadi@umail.ucsb.edu\n",
      "\n",
      "Description: Create sound from images. Can also be termed as \"Visualization of sounds\". What I intend to do with in this assignment is to consider some channels of the image as magnitude spectrum and the remaining channels as the phase spectrum. Then, using these two spectrums, we form the DFT. Once we have the dft, we take the inverse forier transform of the signal. We then, go ahead and listen to this signal. One idea which I would like to venture is by giving the algorithm random images and listening to the sound they produce once the above conversion criteria is followed. Is there some information we can tell about the image?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "\n",
      "from __future__ import print_function\n",
      "from __future__ import division\n",
      "\n",
      "from IPython.display import display, Audio"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets write the function which takes in an image and computes in magnitude spectrum and phase spectrum. Basically, the magnitude spectrum is one channel and the phase spectrum is the sum of the remaining channels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def img_to_spec(img):\n",
      "    if len(img.shape) == 1:\n",
      "        flattened = img[:,:,0].flatten()\n",
      "        mag_spec = flattened*0.5\n",
      "        phase_spec = flattened*0.5\n",
      "    elif len(img.shape) > 1:\n",
      "        mag_spec = img[:,:,0].flatten()\n",
      "        phase_spec = 0.5*((img[:,:,1].flatten()) + (img[:,:,2].flatten()))\n",
      "    else:\n",
      "        print(\"unknown image!\")\n",
      "        mag_spec = array([])\n",
      "        phase_spec = mag_spec\n",
      "    \n",
      "    return {\"mag_spec\": mag_spec, \"phase_spec\":phase_spec}\n",
      "\n",
      "test = imread(\"../hw_2_images/pic.jpg\")\n",
      "imshow(test)\n",
      "dict_spec = img_to_spec(test)\n",
      "print(test.shape)\n",
      "print(dict_spec[\"mag_spec\"].shape)\n",
      "print(dict_spec[\"phase_spec\"].shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we have checked that the length of the resultant magnitude spectrum and the phase spectrum is in sync with the image width * image height. Let us now write a function to convert this spectrum to audio"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def spec_to_audio(spectrum):\n",
      "    magnitude = spectrum[\"mag_spec\"] #magnitude spectrum\n",
      "    phase = spectrum[\"phase_spec\"] #phase spectrum\n",
      "    \n",
      "    window_size = int(magnitude.shape[0]/100) #window size of samples. \"N\" = 100\n",
      "    windows = range(0, magnitude.shape[0], window_size) #list of all windows\n",
      "    \n",
      "    sig = list() #var to store audio signal\n",
      "    \n",
      "    for window in windows:\n",
      "        mag = magnitude[window: window + window_size] #magnitude in the window\n",
      "        phs = phase[window:window + window_size] #phase in the window\n",
      "        \n",
      "        #constructing the frequency domain signal from the magnitude and phase\n",
      "        #the spectrum is of the form mag*cos(phase) - j*mag*sin(phase).\n",
      "        real_part = mag*cos(phs)\n",
      "        img_part = mag*sin(phs)\n",
      "        sig_spec = [complex(real_x, -img_y) for real_x, img_y in zip(real_part, img_part) ]\n",
      "        sig_window = fft.irfft(sig_spec) * 100 #scaling\n",
      "        sig = sig + sig_window.tolist()\n",
      "        \n",
      "    return sig\n",
      "\n",
      "test = spec_to_audio(dict_spec)\n",
      "plot(test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, lets play the signal."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Audio(test, rate = 44100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, that we've gotten everything ready, lets test some images.\n",
      "First image will be a symmetric image, a checkerboad."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#checkerboard_image\n",
      "check_board = imread(\"../hw_2_images/Checkerboard.jpg\")\n",
      "imshow(check_board)\n",
      "check_dict = img_to_spec(check_board)\n",
      "check_sig = spec_to_audio(check_dict)\n",
      "figure()\n",
      "plot(check_sig)\n",
      "Audio(check_sig, rate = 44100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One can notice that the audio changes sometimes. That is due to the fact that \"flatten\" of numpy flattens the arrays row wise (each row gets appended to the previous row). The checkerboard image has alternating white and black checks at the end of the rows. The beginning of the next row starts with a check which is different from the check that the current row begins. Apart from that, there seems to be a pattern for the audio. Also, roughly, as a proof of concept as to why the audio has some sort of periodicity can be observed from the fact that the plot of the signal has 12 groups of similar blobs where is 12 is the number of horizontal blocks present in the checkerboard image."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given that one can definitely observe some characteristics of the image evidently in the generated audio if the image is symmetric, let us take a general natural image and see if we can find some aspects of the image reflect in the audio file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#image of a human\n",
      "lena = imread(\"../hw_2_images/Lenna.png\")\n",
      "imshow(lena)\n",
      "lena_dict = img_to_spec(lena)\n",
      "lena_sig = spec_to_audio(lena_dict)\n",
      "figure()\n",
      "plot(lena_sig)\n",
      "Audio(lena_sig, rate = 44100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As one can notice, there is no correlation as to how the audio signal corresponds to the image provided. The plot of the generated signal has a group of 7 repeating structures (neglecting the amplitude) which might be corresponding to some aspect of the image that is not very clearly evident."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
