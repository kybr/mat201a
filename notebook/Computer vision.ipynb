{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OpenCV](http://opencv.org)\n",
    "...can be difficult to get up and running with Python and Jupyter. Here's some links that might help:\n",
    "- http://www.pyimagesearch.com/2016/12/19/install-opencv-3-on-macos-with-homebrew-the-easy-way (homebrew/macOS)\n",
    "- https://medium.com/@acarabott/installing-opencv3-on-macos-sierra-10-12-2-with-c-11-python-3-ffmpeg-gstreamer-tbb-80413092b57d (alternative)\n",
    "- http://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv (libraries for windows)\n",
    "\n",
    "#### Find API/documetation here:\n",
    "- http://opencv.org/opencv-3-2.html (C/C++)\n",
    "- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "#rcParams['figure.figsize'] = (10, 4)\n",
    "import cv2\n",
    "print('OpenCV v' + cv2.__version__)\n",
    "from IPython.display import clear_output\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.open(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame = cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(frame[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color layers are in wrong order! They go BGR rather than RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "imshow(image_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time video in OpenCV\n",
    "You must stop the video manually before you proceed. Hit **ESC** and then **ii** to interrupt the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        imshow(frame)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-time processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have the image as a numpy array, we can apply any type of image processing to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #gray = flip(gray, axis=0)\n",
    "        imshow(gray)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "- Canny\n",
    "  + http://docs.opencv.org/3.2.0/da/d5c/tutorial_canny_detector.html\n",
    "  + http://docs.opencv.org/3.2.0/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(frame, 40, 120, apertureSize = 3)\n",
    "        imshow(edges)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face detection\n",
    "- CascadeClassifier\n",
    "  + http://docs.opencv.org/3.2.0/db/d28/tutorial_cascade_classifier.html\n",
    "  + http://docs.opencv.org/3.2.0/d1/de5/classcv_1_1CascadeClassifier.html#aaf8181cb63968136476ec4204ffca498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(img):\n",
    "    #cascade = cv2.CascadeClassifier(\"/usr/share/opencv/haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "    # put your file path here....\n",
    "    cascade = cv2.CascadeClassifier(\"/usr/local/Cellar/opencv3/3.2.0/share/OpenCV/haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "    rects = cascade.detectMultiScale(img)\n",
    "\n",
    "    if len(rects) == 0:\n",
    "        return []\n",
    "    rects[:, 2:] += rects[:, :2]\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        rects = detect(frame)\n",
    "        for x1, y1, x2, y2 in rects:\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (127, 255, 0), 2)\n",
    "        imshow(frame)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering across frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "ret, prevframe = capture.read()\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        difference = frame - prevframe\n",
    "        prevframe = frame\n",
    "        imshow(difference)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "ret, prevframe = capture.read()\n",
    "prevframe = cv2.cvtColor(prevframe, cv2.COLOR_BGR2GRAY)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        difference = frame - prevframe\n",
    "        prevframe = frame\n",
    "        imshow(difference, cmap=cm.gray)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 10\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "ret, prevframe = capture.read()\n",
    "prevframe = cv2.cvtColor(prevframe, cv2.COLOR_BGR2GRAY)\n",
    "prevframe = cv2.GaussianBlur(prevframe, (0,0), sigma)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = cv2.GaussianBlur(frame, (0,0), sigma)\n",
    "        difference = frame - prevframe\n",
    "        difference = cv2.GaussianBlur(difference, (0,0), sigma)\n",
    "        prevframe = frame\n",
    "        imshow(difference, cmap=cm.gray)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "- threshold\n",
    "  + http://docs.opencv.org/3.2.0/d7/d4d/tutorial_py_thresholding.html\n",
    "  + http://docs.opencv.org/3.2.0/d7/d1b/group__imgproc__misc.html#gae8a4a146d1ca78c626a53577199e9c57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "capture = cv2.VideoCapture(0)\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        if not ret:\n",
    "            capture.release()\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret, frame = cv2.threshold(frame, threshold, 255, cv2.THRESH_BINARY)\n",
    "        imshow(frame)\n",
    "        show()\n",
    "        clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    capture.release()\n",
    "    print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A way to make the code a little cleaner...\n",
    "def untilInterrupt(loop):\n",
    "    try:\n",
    "        while True:\n",
    "            loop()\n",
    "    except KeyboardInterrupt:\n",
    "        print('Caught Interrupt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "capture = cv2.VideoCapture(0)\n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, frame = cv2.threshold(frame, threshold, 255, cv2.THRESH_BINARY)\n",
    "    imshow(frame)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Blur\n",
    "(Is it though?)\n",
    "- https://en.wikipedia.org/wiki/Motion_blur\n",
    "- https://en.wikipedia.org/wiki/Temporal_anti-aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "ret, prevframe = capture.read()\n",
    "sigma = 30\n",
    "prevframe = cv2.cvtColor(prevframe, cv2.COLOR_BGR2GRAY)\n",
    "prevframe = gaussian_filter(prevframe, sigma)\n",
    "prevframe2 = gaussian_filter(prevframe, sigma)\n",
    "\n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    global prevframe, prevframe2\n",
    "    sumframe = frame / 3 + prevframe / 3 + prevframe2 / 3\n",
    "    prevframe2 = prevframe\n",
    "    prevframe = frame\n",
    "    \n",
    "    imshow(sumframe)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters (FIR/IIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "ret, prevframe = capture.read()\n",
    "sigma = 30\n",
    "prevframe = cv2.cvtColor(prevframe, cv2.COLOR_BGR2GRAY)\n",
    "prevframe = gaussian_filter(prevframe, sigma)\n",
    "\n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # for each pixel, sum the current with the previous with weights\n",
    "    # thats an FIR filter. How do we do IIR?\n",
    "    #\n",
    "    global prevframe\n",
    "    sumframe = frame/4 + prevframe/2\n",
    "    prevframe = sumframe\n",
    "    \n",
    "    imshow(sumframe)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background masking\n",
    "- http://docs.opencv.org/trunk/d1/dc5/tutorial_background_subtraction.html\n",
    "- http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_bg_subtraction/py_bg_subtraction.html\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "#backgroundSubtractor = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "backgroundSubtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = backgroundSubtractor.apply(frame)\n",
    "    imshow(mask)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "#backgroundSubtractor = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "backgroundSubtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = backgroundSubtractor.apply(frame)\n",
    "    imshow(frame * (mask / 255))\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion detection\n",
    "- GaussianBlur\n",
    "  + http://docs.opencv.org/3.2.0/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1\n",
    "  + http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_filtering/py_filtering.html\n",
    "- accumulateWeighted\n",
    "  + http://docs.opencv.org/3.2.0/d7/df3/group__imgproc__motion.html#ga4f9552b541187f61f6818e8d2d826bc7\n",
    "- absdiff\n",
    "  + http://docs.opencv.org/3.2.0/d2/de8/group__core__array.html#ga6fef31bc8c4071cbc114a758a2b79c14\n",
    "- http://docs.opencv.org/3.2.0/d4/d86/group__imgproc__filter.html\n",
    "- http://docs.opencv.org/3.2.0/d4/d13/tutorial_py_filtering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "ret, color_image = capture.read()\n",
    "accum = np.float32(color_image)\n",
    "\n",
    "def draw():\n",
    "    ret, color_image = capture.read()\n",
    "    color_image = cv2.GaussianBlur(color_image, (0,0), 19)\n",
    "    cv2.accumulateWeighted(color_image, accum, 0.320)\n",
    "    difference = cv2.absdiff(color_image, accum.astype(uint8))\n",
    "    imshow(difference)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blob tracking\n",
    "- https://www.learnopencv.com/blob-detection-using-opencv-python-c\n",
    "- http://docs.opencv.org/3.2.0/d0/d7a/classcv_1_1SimpleBlobDetector.html\n",
    "- https://www.makehardware.com/2016/05/19/blob-detection-with-python-and-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "ret, frame = capture.read()\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "accum = np.float32(frame)\n",
    "\n",
    "params = cv2.SimpleBlobDetector_Params()\n",
    "params.minDistBetweenBlobs = 50.0\n",
    "params.filterByInertia = False\n",
    "params.filterByConvexity = False\n",
    "params.filterByColor = False\n",
    "params.filterByCircularity = False\n",
    "params.filterByArea = True\n",
    "params.minArea = 20.0\n",
    "params.maxArea = 500.0\n",
    "params.minThreshold = 40\n",
    "blobdetect = cv2.SimpleBlobDetector_create(params)\n",
    "                             \n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    color_image = cv2.GaussianBlur(frame, (0,0), 19)\n",
    "    cv2.accumulateWeighted(frame, accum, 0.320)\n",
    "    difference = cv2.absdiff(frame, accum.astype(uint8))\n",
    "\n",
    "    keypoints = blobdetect.detect(difference)\n",
    "\n",
    "    for kp in keypoints:\n",
    "        cv2.circle(difference, (int(kp.pt[0]),int(kp.pt[1])), int(kp.size), (255, 0,0), -1)\n",
    "\n",
    "    imshow(difference)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough transform\n",
    "- http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "capture = cv2.VideoCapture(0)\n",
    "sleep(1)\n",
    "ret, frame = capture.read()\n",
    "capture.release()\n",
    "\n",
    "print(shape(frame))\n",
    "\n",
    "frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(frame, 50, 150, apertureSize = 5)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "if lines.any() == None:\n",
    "    raise\n",
    "\n",
    "for rho, theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "\n",
    "    cv2.line(frame, (x1,y1), (x2,y2), color=(255,255,255))\n",
    "\n",
    "imshow(frame) # , cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(frame, 50, 150,apertureSize = 3)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 23)\n",
    "    if lines.any() == None:\n",
    "        raise\n",
    "\n",
    "    for rho, theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "\n",
    "        cv2.line(frame,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    \n",
    "    imshow(frame)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "def draw():\n",
    "    ret, frame = capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize = 3)\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 10\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 12, minLineLength, maxLineGap)\n",
    "    if lines is None:\n",
    "        raise\n",
    "    for x1,y1,x2,y2 in lines[0]:\n",
    "        cv2.line(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "\n",
    "    imshow(frame)\n",
    "    show()\n",
    "    clear_output(wait=True)\n",
    "\n",
    "untilInterrupt(draw)\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*oops!* need to add checks for no lines..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Andrés Cabrera mantaraya36@gmail.com\n",
    "\n",
    "For Course MAT 201A at UCSB\n",
    "\n",
    "This ipython notebook is licensed under the CC-BY-NC-SA license: http://creativecommons.org/licenses/by-nc-sa/4.0/\n",
    "\n",
    "![http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png](http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
