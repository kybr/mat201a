{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "rcParams['figure.figsize'] = (10, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "[Scikit Learn](http://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# most examples here are based on examples from the sklearn docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['DESCR']) # DESCR === header that descibes the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [linearly seperable](https://en.wikipedia.org/wiki/Linear_separability)\n",
    "- [perceptron](https://en.wikipedia.org/wiki/Perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sklearn \"Bunches\", you can use key names as members of the object too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.shape, data['data'].shape # same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target # which data are of which class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target_names # 'setosa'==0, 'versicolor'==1, 'virginica'==2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginicas = argwhere(data.target == list(data.target_names).index('virginica'))[:,0]\n",
    "print(virginicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give me the index of the first occurance of 'virginica' in the list of data.target_names\n",
    "list(data.target_names).index('virginica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.target == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argwhere(data.target == 2)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virginicas = argwhere(data.target == list(data.target_names).index('virginica'))[:,0]\n",
    "print(virginicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 1\n",
    "data.feature_names[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[virginicas].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[virginicas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[virginicas][:,1].mean() # 'sepal width (cm)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[virginicas][:,1].var() # 'sepal width (cm)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem(data.data[virginicas][:,1]) # 'sepal width (cm)'\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosas = argwhere(data.target == list(data.target_names).index('setosa'))[:,0]\n",
    "\n",
    "# 'sepal width (cm)'\n",
    "plot(data.data[virginicas][:,1], label=\"virginicas\")\n",
    "plot(data.data[setosas][:,1], label=\"setosas\")\n",
    "legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see a trend? . . . . . . . . . . . . . These are similar. They are not totally different, but they are not exactly the same either. Also, there's no special relationship between the 10th virginica and the 10th setosa, so plotting them this way is, perhaps, misleading... or, at least, not ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setosas = argwhere(data.target == list(data.target_names).index('setosa'))[:,0]\n",
    "\n",
    "# 'sepal width (cm)'\n",
    "plot(sort(data.data[virginicas][:,1]),label=\"virginicas\")\n",
    "plot(sort(data.data[setosas][:,1]), label=\"setosas\")\n",
    "legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolors = argwhere(data.target == list(data.target_names).index('versicolor'))[:,0]\n",
    "\n",
    "plot(sort(data.data[virginicas][:,1]))\n",
    "plot(sort(data.data[setosas][:,1]))\n",
    "plot(sort(data.data[versicolors][:,1]))\n",
    "\n",
    "title(\"Feature: \" + data.feature_names[1])\n",
    "legend(['virginica', 'setosa', 'versicolor'])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 3\n",
    "\n",
    "plot(sort(data.data[virginicas][:,feature]))\n",
    "plot(sort(data.data[setosas][:,feature]))\n",
    "plot(sort(data.data[versicolors][:,feature]))\n",
    "\n",
    "title(\"Feature: \" + data.feature_names[feature])\n",
    "legend(['virginica', 'setosa', 'versicolor'])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each seems somewhat correlated, but we cannot be sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the first two features for all samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF']) # R, G, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c=data.target connects the class with the sample, then..\n",
    "# cmap=cmap_bold -> color\n",
    "scatter(data.data[:, 0], data.data[:, 1], c=data.target, cmap=cmap_bold)\n",
    "xlabel(data.feature_names[0])\n",
    "ylabel(data.feature_names[1])\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red seems linearly separable, but remember that we're still just looking a 2 of 4 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html#sklearn.dummy.DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy='uniform') # random classification.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set (all the samples, but just the first two features)\n",
    "X = data.data[:,:2]\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step, given training data which has already been classified.\n",
    "clf.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(array([[7.2, 2.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(array([[7.2, 2.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for Machine Learning...\n",
    "0. have data\n",
    "1. create classifier\n",
    "2. train on data (aka 'fit')\n",
    "3. classify new data (aka 'predict')\n",
    "4. compare to a baseline\n",
    "\n",
    "`Dummy` is a random classifier to compare your method with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbor Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data[:, :2]\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors,)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(array([[7.2, 2.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(array([[5.0, 3.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(data.data[:, 0], data.data[:, 1], c=data.target, cmap=cmap_bold)\n",
    "xlabel(data.feature_names[0])\n",
    "ylabel(data.feature_names[1])\n",
    "\n",
    "# show where we asked for predictions...\n",
    "scatter(*zip((7.2, 2.5),(5.0, 3.5)), c='purple', marker='x', lw=8)\n",
    "pass\n",
    "\n",
    "# * https://stackoverflow.com/questions/2921847/what-does-the-star-operator-mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the desicion boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meshgrid(range, range) is line 2d linspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the prediction for each point in the mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_ is by row, c_ is by column\n",
    "# ravel? https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.ravel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = clf.predict(c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "pcolormesh(xx, yy, Z, cmap=cmap_bold)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of neighbors affects the classification boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [5, 10, 15, 50]\n",
    "\n",
    "X = data.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "y = data.target\n",
    "h = .02  # step size in the mesh\n",
    "sp = 1\n",
    "for n in n_neighbors:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n, weights='distance')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    subplot(1,4,sp); sp += 1 \n",
    "    pcolormesh(xx, yy, Z, cmap=cmap_bold)\n",
    "\n",
    "    xlim(xx.min(), xx.max())\n",
    "    ylim(yy.min(), yy.max())\n",
    "    title(\"k = %i\"% (n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distance can be measured in many ways!\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 5\n",
    "\n",
    "X = data.data[:, :2]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "y = data.target\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    figure()\n",
    "    pcolormesh(xx, yy, Z, cmap=cmap_bold)\n",
    "\n",
    "    # Plot also the training points\n",
    "    scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "    xlim(xx.min(), xx.max())\n",
    "    ylim(yy.min(), yy.max())\n",
    "    title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "             % (n_neighbors, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I ask for a prediction using 4 features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 15\n",
    "\n",
    "X = data.data[:, :]  # we only take the first two features. We could\n",
    "                      # avoid this ugly slicing by using a two-dim dataset\n",
    "y = data.target\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights='uniform')\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[7.2, 2.5, 3.0, 3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[7.2, 2.5, 5.0, 2.4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data[120, :] # class == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show a plot of the space of all 4 features would be difficult. We cannot directly visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative probabilistic approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_[xx.ravel(), yy.ravel()] # r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X, y) # supervised learning\n",
    "\n",
    "# make and plot an image that shows predictions as colors\n",
    "Z = clf.predict(c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "pcolormesh(xx, yy, Z, cmap=cmap_bold)\n",
    "\n",
    "# \n",
    "scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "xlim(xx.min(), xx.max())\n",
    "ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assumes that the data takes the form of superpositions (piles) of gausian distributions... which may be a bad assumption. In fact, each of these techniques makes assumptions which may be terrible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianMixture(n_components=3) # number of classes..\n",
    "\n",
    "clf.fit(X) # no y... it ignores the given classes. you just tell it the number of classes (unsupervised).\n",
    "\n",
    "# make and plot an image that shows a grid of predictions as colors\n",
    "Z = clf.predict(c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "pcolormesh(xx, yy, Z, cmap=cmap_bold)\n",
    "\n",
    "#\n",
    "scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "xlim(xx.min(), xx.max())\n",
    "ylim(yy.min(), yy.max()) # try this a few times until the color works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Hyperplanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X, y) # supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Z = clf.predict(c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "pcolormesh(xx, yy, Z, cmap=cmap_bold)\n",
    "\n",
    "#\n",
    "scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
    "xlim(xx.min(), xx.max())\n",
    "ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It creates regions using just lines. We're just using 2 features here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(data.data, data.target) # use all features, all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the actual data which we know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(data.data[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(data.data[50:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What? What's wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(data.data[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# By: Andrés Cabrera mantaraya36@gmail.com\n",
    "\n",
    "For Course MAT 201A at UCSB\n",
    "\n",
    "Adapted by Karl Yerkes\n",
    "\n",
    "This ipython notebook is licensed under the CC-BY-NC-SA license: http://creativecommons.org/licenses/by-nc-sa/4.0/\n",
    "\n",
    "![http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png](http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
