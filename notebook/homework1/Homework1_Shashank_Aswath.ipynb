{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT 201A Spring 2017\n",
    "\n",
    "# HW 1\n",
    "\n",
    "## Author: Shashank Aswath\n",
    "\n",
    "### shashank@mat.ucsb.edu\n",
    "\n",
    "#### This notebook implements a conversion of image file to sound and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all the imports here\n",
    "\n",
    "%pylab inline\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import IPython.core.display\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Convert Image to sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the image\n",
    "image = imread('media/abstract.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out essential information about the image\n",
    "print(type(image), image.shape, image.dtype, len(image), image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the R, G and B components.\n",
    "# Multiply R by 50, G by 100 and B by 200 to get it in the uint16 range. \n",
    "# The above multiplication rule is arbitrary\n",
    "# so that a large number of R samples act as bass, G act as mids and B act as treble\n",
    "soundarray0 = array(((image[:,:,0].astype(int16)- 100) * 50).flat)\n",
    "soundarray1 = array(((image[:,:,1].astype(int16)- 100) * 100).flat)\n",
    "soundarray2 = array(((image[:,:,2].astype(int16)- 100) * 200).flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image into sound and compose a piece based on the following rule:\n",
    "# Arrange samples as R,G,B.\n",
    "# Every one sec, insert a random silence that lasts between 1/4s to 1s\n",
    "prev = np.array([0,0,0], dtype=int16)\n",
    "sampling_rate = 44100\n",
    "for i in range(len(soundarray0)):\n",
    "    temp = np.append(soundarray0[i], [soundarray1[i], soundarray2[i]])\n",
    "    if not i%44100:\n",
    "        print(i)\n",
    "        prev = np.append(prev, np.zeros(random.randint((sampling_rate/4),sampling_rate), dtype=int16))\n",
    "    new_audio_array = np.append(prev, temp)\n",
    "    prev = new_audio_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the output into a wav file\n",
    "wavfile.write('result/abstract.wav', 44100, new_audio_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the output\n",
    "!afplay result/abstract.wav\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the audio\n",
    "IPython.display.Audio('result/abstract.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Convert generated sound back to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the sound file\n",
    "samplingRate, inputAudio = wavfile.read('result/abstract.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out essential information about the audio\n",
    "print(len(inputAudio), type(inputAudio), inputAudio.shape, inputAudio.size, inputAudio.dtype, samplingRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since silence samples were introduced, the image can be larger than above. Determine a good size\n",
    "700*1050*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the audio into an RGB structure and divide the samples to get it in the uint8 range\n",
    "image_from_audio = inputAudio[:2205000].reshape(700,1050,3)\n",
    "image_from_audio = image_from_audio/100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the output\n",
    "imshow(image_from_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output image\n",
    "imsave('result/NewAbstract.jpg', image_from_audio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
